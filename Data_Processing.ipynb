{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d07786",
   "metadata": {},
   "source": [
    "Examine the data structure in our raster files and shp files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde9c5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extracting TIF Metadata ---\n",
      "                      file    type        crs  width  height                                              transform    dtype         nodata  bands  resolution_x  resolution_y driver\n",
      "0         5_Bf_2010_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float64 -1.700000e+308      1      0.083333     -0.083333  GTiff\n",
      "1         5_Bf_2015_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.400000e+38      1      0.083333     -0.083333  GTiff\n",
      "2         5_Ch_2010_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float64 -1.700000e+308      1      0.083333     -0.083333  GTiff\n",
      "3         5_Ch_2015_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.400000e+38      1      0.083333     -0.083333  GTiff\n",
      "4         5_Ct_2010_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float64 -1.700000e+308      1      0.083333     -0.083333  GTiff\n",
      "5         5_Ct_2015_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.400000e+38      1      0.083333     -0.083333  GTiff\n",
      "6         5_Dk_2010_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float64 -1.700000e+308      1      0.083333     -0.083333  GTiff\n",
      "7         5_Dk_2015_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.400000e+38      1      0.083333     -0.083333  GTiff\n",
      "8         5_Gt_2010_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float64 -1.700000e+308      1      0.083333     -0.083333  GTiff\n",
      "9         5_Gt_2015_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.400000e+38      1      0.083333     -0.083333  GTiff\n",
      "10        5_Ho_2010_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float64 -1.700000e+308      1      0.083333     -0.083333  GTiff\n",
      "11        5_Ho_2015_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.400000e+38      1      0.083333     -0.083333  GTiff\n",
      "12        5_Pg_2010_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float64 -1.700000e+308      1      0.083333     -0.083333  GTiff\n",
      "13        5_Pg_2015_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.400000e+38      1      0.083333     -0.083333  GTiff\n",
      "14        5_Sh_2010_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float64 -1.700000e+308      1      0.083333     -0.083333  GTiff\n",
      "15        5_Sh_2015_Da.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.400000e+38      1      0.083333     -0.083333  GTiff\n",
      "16  GLW4-2020.D-DA.BFL.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.402823e+38      1      0.083333     -0.083333  GTiff\n",
      "17  GLW4-2020.D-DA.CHK.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.402823e+38      1      0.083333     -0.083333  GTiff\n",
      "18  GLW4-2020.D-DA.CTL.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.402823e+38      1      0.083333     -0.083333  GTiff\n",
      "19  GLW4-2020.D-DA.GTS.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.402823e+38      1      0.083333     -0.083333  GTiff\n",
      "20  GLW4-2020.D-DA.PGS.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.402823e+38      1      0.083333     -0.083333  GTiff\n",
      "21  GLW4-2020.D-DA.SHP.tif  raster  EPSG:4326   4320    2160  (0.0833333333, 0.0, -180.0, 0.0, -0.0833333333, 90.0)  float32  -3.402823e+38      1      0.083333     -0.083333  GTiff\n",
      "\n",
      "‚ö†Ô∏è  Inconsistent fields for TIFs: {'dtype': ['float64', 'float32'], 'nodata': [-1.7e+308, -3.3999999521443642e+38, -3.4028234663852886e+38]}\n",
      "\n",
      "--- Extracting SHP Metadata ---\n",
      "                         file    type                                                                                                                                                                                                                                                                                                                               crs           geometry_types                                                                                                                                                                                                                                    properties_schema                                            bounds          driver  feature_count encoding\n",
      "0  cb_2018_us_county_500k.shp  vector  GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4269\"]]  [Polygon, MultiPolygon]                                                                    {'STATEFP': 'str:2', 'COUNTYFP': 'str:3', 'COUNTYNS': 'str:8', 'AFFGEOID': 'str:14', 'GEOID': 'str:5', 'NAME': 'str:100', 'LSAD': 'str:2', 'ALAND': 'int:14', 'AWATER': 'int:14'}   (-179.148909, -14.548699, 179.77847, 71.365162)  ESRI Shapefile           3233     None\n",
      "1  cb_2023_us_county_500k.shp  vector  GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4269\"]]  [Polygon, MultiPolygon]  {'STATEFP': 'str:2', 'COUNTYFP': 'str:3', 'COUNTYNS': 'str:8', 'GEOIDFQ': 'str:14', 'GEOID': 'str:5', 'NAME': 'str:100', 'NAMELSAD': 'str:100', 'STUSPS': 'str:2', 'STATE_NAME': 'str:100', 'LSAD': 'str:2', 'ALAND': 'int:14', 'AWATER': 'int:14'}   (-179.146711, -14.548699, 179.77847, 71.387815)  ESRI Shapefile           3235     None\n",
      "2   cb_2023_us_state_500k.shp  vector  GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4269\"]]  [Polygon, MultiPolygon]                                                                        {'STATEFP': 'str:2', 'STATENS': 'str:8', 'GEOIDFQ': 'str:11', 'GEOID': 'str:2', 'STUSPS': 'str:2', 'NAME': 'str:100', 'LSAD': 'str:2', 'ALAND': 'int:14', 'AWATER': 'int:14'}   (-179.146711, -14.548699, 179.77847, 71.387815)  ESRI Shapefile             56     None\n",
      "3      tl_2020_us_zcta520.shp  vector  GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4269\"]]  [Polygon, MultiPolygon]                                               {'ZCTA5CE20': 'str:5', 'GEOID20': 'str:5', 'CLASSFP20': 'str:2', 'MTFCC20': 'str:5', 'FUNCSTAT20': 'str:1', 'ALAND20': 'int:14', 'AWATER20': 'int:14', 'INTPTLAT20': 'str:11', 'INTPTLON20': 'str:12'}  (-176.696692, -14.373776, 145.830505, 71.341324)  ESRI Shapefile          33791     None\n",
      "\n",
      "‚ö†Ô∏è  Inconsistent fields for SHPs: {'properties_schema': [\"[('AFFGEOID', 'str:14'), ('ALAND', 'int:14'), ('AWATER', 'int:14'), ('COUNTYFP', 'str:3'), ('COUNTYNS', 'str:8'), ('GEOID', 'str:5'), ('LSAD', 'str:2'), ('NAME', 'str:100'), ('STATEFP', 'str:2')]\", \"[('ALAND', 'int:14'), ('AWATER', 'int:14'), ('COUNTYFP', 'str:3'), ('COUNTYNS', 'str:8'), ('GEOID', 'str:5'), ('GEOIDFQ', 'str:14'), ('LSAD', 'str:2'), ('NAME', 'str:100'), ('NAMELSAD', 'str:100'), ('STATEFP', 'str:2'), ('STATE_NAME', 'str:100'), ('STUSPS', 'str:2')]\", \"[('ALAND', 'int:14'), ('AWATER', 'int:14'), ('GEOID', 'str:2'), ('GEOIDFQ', 'str:11'), ('LSAD', 'str:2'), ('NAME', 'str:100'), ('STATEFP', 'str:2'), ('STATENS', 'str:8'), ('STUSPS', 'str:2')]\", \"[('ALAND20', 'int:14'), ('AWATER20', 'int:14'), ('CLASSFP20', 'str:2'), ('FUNCSTAT20', 'str:1'), ('GEOID20', 'str:5'), ('INTPTLAT20', 'str:11'), ('INTPTLON20', 'str:12'), ('MTFCC20', 'str:5'), ('ZCTA5CE20', 'str:5')]\"]}\n",
      "\n",
      "üí° Note: 'properties_schema' field consistency check shows differences in field names or types.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import rasterio\n",
    "import fiona\n",
    "import pandas as pd\n",
    "from shapely.geometry import shape # Useful for more advanced geometry analysis\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Configuration ---\n",
    "root_dir = pathlib.Path(\"/Users/faizahmad/Desktop/grok_live/data\")  # üìÇ Adjust this path\n",
    "\n",
    "# --- Function to Extract Metadata from TIF (Raster) Files (from previous version, unchanged) ---\n",
    "def extract_tif_metadata(directory: pathlib.Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts common metadata from GeoTIFF files in a given directory.\n",
    "    \"\"\"\n",
    "    tif_files = sorted(directory.glob(\"*.tif\"))\n",
    "    records = []\n",
    "    for f in tif_files:\n",
    "        try:\n",
    "            with rasterio.open(f) as src:\n",
    "                meta = src.meta\n",
    "                records.append({\n",
    "                    \"file\": f.name,\n",
    "                    \"type\": \"raster\",\n",
    "                    \"crs\": meta[\"crs\"].to_string() if meta[\"crs\"] else None,\n",
    "                    \"width\": meta[\"width\"],\n",
    "                    \"height\": meta[\"height\"],\n",
    "                    \"transform\": tuple(round(x, 10) for x in meta[\"transform\"][:6]),\n",
    "                    \"dtype\": meta[\"dtype\"],\n",
    "                    \"nodata\": meta[\"nodata\"],\n",
    "                    \"bands\": meta[\"count\"],\n",
    "                    \"resolution_x\": round(meta[\"transform\"].a, 10),\n",
    "                    \"resolution_y\": round(meta[\"transform\"].e, 10),\n",
    "                    \"driver\": meta[\"driver\"],\n",
    "                })\n",
    "        except rasterio.errors.RasterioIOError as e:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {f.name}: Not a valid GeoTIFF or read error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  An unexpected error occurred with {f.name}: {e}\")\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# --- ‚ù∑ Further Improved Function to Extract Metadata from SHP (Vector) Files ---\n",
    "def extract_shp_metadata(directory: pathlib.Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts common metadata from Shapefile files in a given directory.\n",
    "    \"\"\"\n",
    "    shp_files = sorted(directory.glob(\"*.shp\"))\n",
    "    records = []\n",
    "    for f in shp_files:\n",
    "        try:\n",
    "            with fiona.open(f) as src:\n",
    "                # --- Robustly extract properties schema ---\n",
    "                properties_schema = {}\n",
    "                if 'properties' in src.schema and src.schema['properties']:\n",
    "                    for prop_name, prop_details in src.schema[\"properties\"].items():\n",
    "                        if isinstance(prop_details, dict) and 'type' in prop_details:\n",
    "                            properties_schema[prop_name] = prop_details['type']\n",
    "                        else:\n",
    "                            # Fallback if 'type' key is missing or prop_details is not a dict\n",
    "                            properties_schema[prop_name] = str(prop_details) # Coerce to string for inspection\n",
    "                else:\n",
    "                    properties_schema = {} # No properties found or empty schema\n",
    "\n",
    "                # --- Get unique geometry types (sampling for performance) ---\n",
    "                unique_geometry_types = set()\n",
    "                try:\n",
    "                    for i, feature in enumerate(src):\n",
    "                        if i >= 1000: # Sample up to 1000 features to avoid slow processing\n",
    "                            break\n",
    "                        if feature and 'geometry' in feature and feature['geometry'] and 'type' in feature['geometry']:\n",
    "                            unique_geometry_types.add(feature['geometry']['type'])\n",
    "                except StopIteration:\n",
    "                    pass # Handle empty shapefiles gracefully\n",
    "                except Exception as geom_e:\n",
    "                    print(f\"‚ö†Ô∏è  Error getting geometry type for {f.name}: {geom_e}\")\n",
    "                    unique_geometry_types.add(\"Error_reading_geometry\")\n",
    "\n",
    "\n",
    "                records.append({\n",
    "                    \"file\": f.name,\n",
    "                    \"type\": \"vector\",\n",
    "                    \"crs\": src.crs_wkt,  # WKT string for CRS\n",
    "                    \"geometry_types\": list(unique_geometry_types) if unique_geometry_types else [], # List of detected geometry types\n",
    "                    \"properties_schema\": properties_schema, # Field names and types\n",
    "                    \"bounds\": src.bounds, # (min_x, min_y, max_x, max_y)\n",
    "                    \"driver\": src.driver,\n",
    "                    \"feature_count\": len(src), # Number of features in the shapefile\n",
    "                    \"encoding\": src.encoding if hasattr(src, 'encoding') else None, # Character encoding for DBF\n",
    "                })\n",
    "        except fiona.errors.DriverError as e:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {f.name}: Not a valid Shapefile or read error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  An unexpected error occurred with {f.name}: {e}\")\n",
    "            # This line will help diagnose the exact structure if the above fixes don't work\n",
    "            # if 'src' in locals():\n",
    "            #     print(f\"Debug: Schema for {f.name}: {src.schema}\")\n",
    "            #     if 'properties' in src.schema:\n",
    "            #         print(f\"Debug: Properties for {f.name}: {src.schema['properties']}\")\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# --- ‚ù∏ Run Extraction and Analysis ---\n",
    "\n",
    "print(\"--- Extracting TIF Metadata ---\")\n",
    "df_tifs = extract_tif_metadata(root_dir)\n",
    "if not df_tifs.empty:\n",
    "    print(df_tifs.to_string()) # Use .to_string() to avoid truncation\n",
    "    print(\"\\n‚ö†Ô∏è  Inconsistent fields for TIFs:\", end=\" \")\n",
    "    tif_problems = {\n",
    "        col: df_tifs[col].unique().tolist()\n",
    "        for col in [\"crs\", \"width\", \"height\", \"transform\", \"dtype\", \"nodata\", \"bands\", \"resolution_x\", \"resolution_y\", \"driver\"]\n",
    "        if len(df_tifs[col].unique()) > 1\n",
    "    }\n",
    "    print(tif_problems if tif_problems else \"None üéâ\")\n",
    "else:\n",
    "    print(\"No TIF files found or processed.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Extracting SHP Metadata ---\")\n",
    "df_shps = extract_shp_metadata(root_dir)\n",
    "if not df_shps.empty:\n",
    "    print(df_shps.to_string()) # Use .to_string() to avoid truncation\n",
    "\n",
    "    print(\"\\n‚ö†Ô∏è  Inconsistent fields for SHPs:\", end=\" \")\n",
    "    # For SHP consistency, 'bounds' and 'feature_count' are almost certainly\n",
    "    # going to be different for each file, so exclude them from the default check.\n",
    "\n",
    "    # Convert 'properties_schema' dictionary to a sorted string for hashing\n",
    "    properties_schema_str = df_shps['properties_schema'].apply(lambda x: str(sorted(x.items())))\n",
    "    geometry_types_hashable = df_shps['geometry_types'].apply(lambda x: tuple(sorted(x)))\n",
    "\n",
    "    shp_problems = {\n",
    "        \"crs\": df_shps[\"crs\"].unique().tolist() if len(df_shps[\"crs\"].unique()) > 1 else None,\n",
    "        \"geometry_types\": geometry_types_hashable.unique().tolist() if len(geometry_types_hashable.unique()) > 1 else None,\n",
    "        \"properties_schema\": properties_schema_str.unique().tolist() if len(properties_schema_str.unique()) > 1 else None,\n",
    "        \"driver\": df_shps[\"driver\"].unique().tolist() if len(df_shps[\"driver\"].unique()) > 1 else None,\n",
    "        \"encoding\": df_shps[\"encoding\"].unique().tolist() if len(df_shps[\"encoding\"].unique()) > 1 else None,\n",
    "    }\n",
    "    # Remove None values\n",
    "    shp_problems = {k: v for k, v in shp_problems.items() if v is not None}\n",
    "    print(shp_problems if shp_problems else \"None üéâ\")\n",
    "\n",
    "    # Optional: More specific check for schema consistency, if fields should be identical\n",
    "    if len(properties_schema_str.unique()) > 1:\n",
    "        print(\"\\nüí° Note: 'properties_schema' field consistency check shows differences in field names or types.\")\n",
    "        # You could add logic here to print the differing schemas for inspection\n",
    "else:\n",
    "    print(\"No SHP files found or processed.\")\n",
    "\n",
    "# --- Optional: Combine and Analyze if you need a single DataFrame ---\n",
    "# You can concatenate them if you add a 'type' column to distinguish\n",
    "# combined_df = pd.concat([df_tifs, df_shps], ignore_index=True)\n",
    "# print(\"\\n--- Combined Metadata (if applicable) ---\")\n",
    "# print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f944b34",
   "metadata": {},
   "source": [
    "For the livestock dataset: Calculating mean, count and headcount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496595b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from rasterstats import zonal_stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "RASTER_DIR = Path(\"/Users/faizahmad/Desktop/NewLiv/data\")\n",
    "COUNTY_SHP = Path(\"/Users/faizahmad/Desktop/NewLiv/data/cb_2023_us_county_500k.shp\")\n",
    "OUT_CSV    = Path(\"county_livestock_2010_2015_2020.csv\")\n",
    "CORES      = max(os.cpu_count() - 1, 1)\n",
    "\n",
    "def load_counties():\n",
    "    g = gpd.read_file(COUNTY_SHP).to_crs(\"EPSG:4326\")\n",
    "    geoids = [c for c in g.columns if c.upper().startswith(\"GEOID\")]\n",
    "    col = \"GEOID\" if \"GEOID\" in geoids else sorted(geoids, key=len)[0]\n",
    "    if col != \"GEOID\":\n",
    "        g = g.rename(columns={col: \"GEOID\"})\n",
    "    if \"ALAND\" in g.columns:\n",
    "        g[\"area_km2\"] = g[\"ALAND\"] / 1e6\n",
    "    else:\n",
    "        g[\"area_km2\"] = g.to_crs(5070).geometry.area / 1e6\n",
    "    return g[[\"GEOID\",\"area_km2\",\"geometry\"]]\n",
    "\n",
    "def one_raster(tif, counties):\n",
    "    year = re.search(r\"(\\d{4})\", tif.name).group(1)\n",
    "    species = tif.stem.split('.')[-1]\n",
    "    stats = zonal_stats(\n",
    "        counties, tif,\n",
    "        stats=[\"mean\",\"count\"],\n",
    "        nodata=None,\n",
    "        all_touched=True\n",
    "    )\n",
    "    df = pd.DataFrame(stats)\n",
    "    df[\"GEOID\"] = counties[\"GEOID\"].values\n",
    "    df[\"year\"]  = year\n",
    "    df[\"species\"] = species\n",
    "    df[\"head_count\"] = df[\"mean\"] * counties[\"area_km2\"]\n",
    "    return df[[\"GEOID\",\"year\",\"species\",\"head_count\",\"mean\",\"count\"]].rename(\n",
    "        columns={\"mean\":\"mean_density\",\"count\":\"cell_count\"}\n",
    "    )\n",
    "\n",
    "def run_batch():\n",
    "    counties = load_counties()\n",
    "    tifs = sorted(RASTER_DIR.glob(\"*.tif\"))\n",
    "    pieces = []\n",
    "    with ThreadPoolExecutor(max_workers=CORES) as ex:\n",
    "        futs = {ex.submit(one_raster, tif, counties): tif for tif in tifs}\n",
    "        for f in tqdm(as_completed(futs), total=len(futs), desc=\"processing\"):\n",
    "            pieces.append(f.result())\n",
    "    out = pd.concat(pieces, ignore_index=True)\n",
    "    out.to_csv(OUT_CSV, index=False)\n",
    "    return out\n",
    "\n",
    "df = run_batch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25388ad5",
   "metadata": {},
   "source": [
    "For the livestock datset core code that ensures robustness in the process to use NLCD asset to facillitate our computation (Using NLCD Agri Land \"weighted_mean\": weighted_mean, \"std_dev\": std_dev, \"std_error\": std_error, \"head_count\": head_count, \"area_usable_km2\": usable_area_km2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install rasterio\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask as rio_mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.windows import from_bounds, intersection\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from math import radians, cos\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path(\"/content/drive/MyDrive/NewLiv/data\")\n",
    "COUNTY_SHP = DATA_DIR / \"cb_2023_us_county_500k.shp\"\n",
    "NLCD_RASTER = DATA_DIR / \"Annual_NLCD_LndCov_2019_CU_C1V1.tif\"\n",
    "OUT_DIR = DATA_DIR / \"temp_county_stats\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "CORES = os.cpu_count() or 1\n",
    "COMBINED_OUT = DATA_DIR / \"combined_livestock_stats.csv\"\n",
    "\n",
    "# Land cover classes (NLCD codes) based on metadata\n",
    "LAND_USE_CLASSES = {\n",
    "    \"cropland\": [82],  # Cultivated Crops\n",
    "    \"grassland\": [71],  # Grassland/Herbaceous\n",
    "    \"pasture\": [81],   # Pasture/Hay\n",
    "    \"permanent_crops\": [],\n",
    "    \"water_bodies\": [11, 12],\n",
    "    \"high_pop\": [24],\n",
    "    \"other_exclusions\": [21, 22, 23, 31, 52, 90, 95]\n",
    "}\n",
    "\n",
    "# Species mapping\n",
    "code2name = {\n",
    "    \"CH\": \"chicken\", \"CHK\": \"chicken\", \"PG\": \"pig\", \"PGS\": \"pig\",\n",
    "    \"CT\": \"cattle\", \"CTL\": \"cattle\", \"GT\": \"goat\", \"GTS\": \"goat\",\n",
    "    \"SH\": \"sheep\", \"SHP\": \"sheep\", \"BF\": \"buffalo\", \"BFL\": \"buffalo\",\n",
    "    \"DK\": \"duck\", \"HO\": \"horse\"\n",
    "}\n",
    "\n",
    "# Helper Functions\n",
    "def load_counties():\n",
    "    \"\"\"Load and prepare county shapefile.\"\"\"\n",
    "    g = gpd.read_file(COUNTY_SHP)\n",
    "    geoids = [c for c in g.columns if c.upper().startswith(\"GEOID\")]\n",
    "    col = \"GEOID\" if \"GEOID\" in geoids else sorted(geoids, key=len)[0]\n",
    "    if col != \"GEOID\":\n",
    "        g = g.rename(columns={col: \"GEOID\"})\n",
    "    g[\"GEOID\"] = g[\"GEOID\"].str.zfill(5)\n",
    "    g[\"area_km2\"] = g[\"ALAND\"] / 1e6 if \"ALAND\" in g.columns else g.to_crs(5070).geometry.area / 1e6\n",
    "    g = g.to_crs(\"EPSG:4326\")\n",
    "    return g[[\"GEOID\", \"area_km2\", \"geometry\"]]\n",
    "\n",
    "def compute_weighted_mean(data, nodata, geometry, transform, county_area_km2):\n",
    "    \"\"\"Compute weighted mean density, standard deviation, and standard error.\"\"\"\n",
    "    valid_data = data[data != nodata]\n",
    "    if len(valid_data) == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    # Use accurate cell area based on latitude\n",
    "    centroid_lat = geometry.centroid.y\n",
    "    cell_area = (transform.a * 111.32 * np.cos(np.radians(centroid_lat))) * (abs(transform.e) * 111.32)\n",
    "    weights = np.ones_like(valid_data) * cell_area\n",
    "    weighted_mean = np.average(valid_data, weights=weights) if len(valid_data) > 0 else np.nan\n",
    "    std_dev = np.std(valid_data) if len(valid_data) > 0 else np.nan\n",
    "    std_error = std_dev / np.sqrt(len(valid_data)) if len(valid_data) > 0 else np.nan\n",
    "    return weighted_mean, std_dev, std_error\n",
    "\n",
    "def bounds_overlap(bounds1, bounds2):\n",
    "    \"\"\"Check if two bounding boxes overlap.\"\"\"\n",
    "    return not (bounds1[0] > bounds2[2] or bounds1[2] < bounds2[0] or bounds1[1] > bounds2[3] or bounds1[3] < bounds2[1])\n",
    "\n",
    "def extract_species_from_filename(filename):\n",
    "    \"\"\"Extract species code from raster filename based on known patterns.\"\"\"\n",
    "    match_glw4 = re.search(r\"GLW4-\\d{4}\\.D-DA\\.([A-Z]{3})\\.tif\", filename)\n",
    "    if match_glw4:\n",
    "        return match_glw4.group(1)\n",
    "    match_5_da = re.search(r\"5_([A-Za-z]{2})_\\d{4}_Da\\.tif\", filename)\n",
    "    if match_5_da:\n",
    "        return match_5_da.group(1).upper()\n",
    "    return \"\"\n",
    "\n",
    "def compute_idw_density(geoid, species, year, counties, livestock_raster_paths):\n",
    "    \"\"\"Compute IDW-based density for counties with zero agricultural area.\"\"\"\n",
    "    county = counties[counties[\"GEOID\"] == geoid].iloc[0]\n",
    "    centroid = county.geometry.centroid\n",
    "    counties_proj = counties.to_crs(\"EPSG:5070\")\n",
    "    county_proj = gpd.GeoSeries([centroid], crs=\"EPSG:4326\").to_crs(\"EPSG:5070\").iloc[0]\n",
    "    neighbors = counties_proj[counties_proj.geometry.distance(county_proj) < 11000]\n",
    "    weights = []\n",
    "    densities = []\n",
    "    for _, neighbor in neighbors.iterrows():\n",
    "        if neighbor[\"GEOID\"] == geoid:\n",
    "            continue\n",
    "        neighbor_csv = OUT_DIR / f\"county_{neighbor['GEOID']}_stats.csv\"\n",
    "        if neighbor_csv.exists():\n",
    "            df = pd.read_csv(neighbor_csv)\n",
    "            density_val = df[(df[\"year\"] == year) & (df[\"species\"] == species)][\"weighted_mean\"]\n",
    "            if not density_val.empty and not np.isnan(density_val.iloc[0]):\n",
    "                dist = county_proj.distance(neighbor.geometry)\n",
    "                if dist > 0:\n",
    "                    weights.append(1 / dist)\n",
    "                    densities.append(density_val.iloc[0])\n",
    "    if weights:\n",
    "        return np.average(densities, weights=weights)\n",
    "    return np.nan\n",
    "\n",
    "def resample_nlcd_to_livestock(nlcd_src, livestock_src):\n",
    "    \"\"\"Resample NLCD raster to match livestock raster resolution.\"\"\"\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        nlcd_src.crs, livestock_src.crs, livestock_src.width, livestock_src.height,\n",
    "        *nlcd_src.bounds\n",
    "    )\n",
    "    nlcd_resampled = np.zeros((livestock_src.height, livestock_src.width), dtype=nlcd_src.dtypes[0])\n",
    "    reproject(\n",
    "        source=rasterio.band(nlcd_src, 1),\n",
    "        destination=nlcd_resampled,\n",
    "        src_transform=nlcd_src.transform,\n",
    "        src_crs=nlcd_src.crs,\n",
    "        dst_transform=transform,\n",
    "        dst_crs=livestock_src.crs,\n",
    "        resampling=Resampling.nearest\n",
    "    )\n",
    "    return nlcd_resampled, transform\n",
    "\n",
    "def process_county_chunk(county_chunk, nlcd_raster_path, livestock_raster_paths, counties):\n",
    "    \"\"\"Process a chunk of counties with optimized raster handling.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # --- START of efficiency fix ---\n",
    "    # Perform expensive raster operations once per chunk.\n",
    "    # The CRS is consistently EPSG:4326 for all rasters, making this simpler.\n",
    "    with rasterio.open(nlcd_raster_path) as nlcd_src:\n",
    "        with rasterio.open(livestock_raster_paths[0]) as liv_src:\n",
    "            # Check for CRS consistency before resampling\n",
    "            if nlcd_src.crs != liv_src.crs:\n",
    "                print(f\"Warning: NLCD ({nlcd_src.crs}) and livestock ({liv_src.crs}) CRSs don't match. Reprojecting NLCD.\")\n",
    "\n",
    "            nlcd_resampled, nlcd_transform_resampled = resample_nlcd_to_livestock(nlcd_src, liv_src)\n",
    "            nlcd_bounds = nlcd_src.bounds\n",
    "\n",
    "    # --- END of efficiency fix ---\n",
    "\n",
    "    for _, county in county_chunk.iterrows():\n",
    "        gc.collect()\n",
    "        geoid = county[\"GEOID\"]\n",
    "        geometry_4326 = county[\"geometry\"]\n",
    "\n",
    "        # Use the CRS from the resampled NLCD/livestock raster for consistency.\n",
    "        county_geom_proj = gpd.GeoSeries([geometry_4326], crs=\"EPSG:4326\").to_crs(rasterio.open(livestock_raster_paths[0]).crs).iloc[0]\n",
    "        county_bounds_proj = county_geom_proj.bounds\n",
    "\n",
    "        usable_area_km2 = 0.0\n",
    "\n",
    "        if bounds_overlap(county_bounds_proj, nlcd_bounds):\n",
    "            try:\n",
    "                # Use the resampled NLCD data and its transform\n",
    "                county_window = from_bounds(*county_bounds_proj, nlcd_transform_resampled)\n",
    "                clamped_window = intersection(county_window, from_bounds(*nlcd_bounds, nlcd_transform_resampled))\n",
    "\n",
    "                if clamped_window.width > 0 and clamped_window.height > 0:\n",
    "                    chunk = nlcd_resampled[\n",
    "                        int(clamped_window.row_off):int(clamped_window.row_off + clamped_window.height),\n",
    "                        int(clamped_window.col_off):int(clamped_window.col_off + clamped_window.width)\n",
    "                    ]\n",
    "\n",
    "                    centroid_lat = county_geom_proj.centroid.y\n",
    "                    # Correct cell area calculation\n",
    "                    cell_area_km2 = (nlcd_transform_resampled.a * 111.32 * np.cos(np.radians(centroid_lat))) * (abs(nlcd_transform_resampled.e) * 111.32)\n",
    "\n",
    "                    exclude_mask = (\n",
    "                        np.isin(chunk, LAND_USE_CLASSES[\"water_bodies\"]) |\n",
    "                        np.isin(chunk, LAND_USE_CLASSES[\"high_pop\"]) |\n",
    "                        np.isin(chunk, LAND_USE_CLASSES[\"other_exclusions\"])\n",
    "                    )\n",
    "\n",
    "                    agri_cells = (\n",
    "                        np.isin(chunk, LAND_USE_CLASSES[\"cropland\"]) |\n",
    "                        np.isin(chunk, LAND_USE_CLASSES[\"grassland\"]) |\n",
    "                        np.isin(chunk, LAND_USE_CLASSES[\"pasture\"])\n",
    "                    ) & ~exclude_mask\n",
    "\n",
    "                    usable_area_km2 = np.sum(agri_cells) * cell_area_km2\n",
    "\n",
    "                    # More robust check for usable area\n",
    "                    if usable_area_km2 < 0.1 or usable_area_km2 > county[\"area_km2\"] * 1.5:\n",
    "                        print(f\"Warning: Unusual usable area ({usable_area_km2:.2f} km¬≤) for county {geoid}, using full county area.\")\n",
    "                        usable_area_km2 = county[\"area_km2\"]\n",
    "\n",
    "            except (ValueError, rasterio.errors.RasterioIOError) as e:\n",
    "                print(f\"Error processing NLCD for county {geoid}: {e}. Falling back to total area.\")\n",
    "                usable_area_km2 = county[\"area_km2\"]\n",
    "        else:\n",
    "            usable_area_km2 = county[\"area_km2\"]\n",
    "\n",
    "        stats = []\n",
    "        for tif_path in livestock_raster_paths:\n",
    "            gc.collect()\n",
    "            with rasterio.open(tif_path) as src:\n",
    "                year = re.search(r\"(\\d{4})\", Path(tif_path).name).group(1)\n",
    "                species_code = extract_species_from_filename(Path(tif_path).name)\n",
    "                species = code2name.get(species_code, species_code.lower())\n",
    "                nodata = src.nodata if src.nodata is not None else np.nan\n",
    "\n",
    "                # Check for overlap and process\n",
    "                weighted_mean, std_dev, std_error = np.nan, np.nan, np.nan\n",
    "                if bounds_overlap(county_bounds_proj, src.bounds):\n",
    "                    try:\n",
    "                        # Use rio_mask for more accurate clipping\n",
    "                        out_image, out_transform = rio_mask(src, [county_geom_proj], crop=True, all_touched=True)\n",
    "                        if out_image.size > 0:\n",
    "                            weighted_mean, std_dev, std_error = compute_weighted_mean(\n",
    "                                out_image[0], nodata, county_geom_proj, out_transform, county[\"area_km2\"]\n",
    "                            )\n",
    "                    except (ValueError, rasterio.errors.RasterioIOError) as e:\n",
    "                        print(f\"Error processing {species} raster for county {geoid}: {e}\")\n",
    "                        weighted_mean = np.nan\n",
    "\n",
    "                # Handle zero agricultural area with IDW\n",
    "                if usable_area_km2 < 0.1 and not np.isnan(weighted_mean):\n",
    "                    weighted_mean = compute_idw_density(geoid, species, year, counties, livestock_raster_paths)\n",
    "                    std_dev, std_error = np.nan, np.nan\n",
    "\n",
    "                area_for_calc = usable_area_km2 if usable_area_km2 > 0.1 else county[\"area_km2\"]\n",
    "                head_count = weighted_mean * area_for_calc if not np.isnan(weighted_mean) else np.nan\n",
    "\n",
    "                stats.append({\n",
    "                    \"GEOID\": geoid, \"year\": year, \"species\": species,\n",
    "                    \"weighted_mean\": weighted_mean, \"std_dev\": std_dev, \"std_error\": std_error,\n",
    "                    \"head_count\": head_count, \"area_usable_km2\": usable_area_km2\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(stats)\n",
    "        out_path = OUT_DIR / f\"county_{geoid}_stats.csv\"\n",
    "        df.to_csv(out_path, index=False)\n",
    "        results.append(out_path)\n",
    "    return results\n",
    "\n",
    "def combine_csvs(out_paths):\n",
    "    \"\"\"Combine all county CSV files into a single CSV.\"\"\"\n",
    "    if not out_paths:\n",
    "        print(\"No county stats files were generated to combine.\")\n",
    "        return\n",
    "    combined_df = pd.concat([pd.read_csv(f) for f in out_paths], ignore_index=True)\n",
    "    combined_df.to_csv(COMBINED_OUT, index=False)\n",
    "    print(f\"\\n‚úÖ Combined CSV saved to: {COMBINED_OUT}\")\n",
    "\n",
    "def main_processing(livestock_raster_paths, counties, chunk_size=5):\n",
    "    \"\"\"Orchestrate parallel processing of all counties.\"\"\"\n",
    "    out_paths = []\n",
    "    county_chunks = [counties[i:i + chunk_size] for i in range(0, len(counties), chunk_size)]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=CORES) as executor:\n",
    "        futures = {\n",
    "            executor.submit(\n",
    "                process_county_chunk, chunk, NLCD_RASTER, livestock_raster_paths, counties\n",
    "            ): chunk for chunk in county_chunks\n",
    "        }\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing chunks\"):\n",
    "            out_paths.extend(future.result())\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved {len(out_paths)} county CSVs to: {OUT_DIR}\")\n",
    "    combine_csvs(out_paths)\n",
    "    return out_paths\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading counties...\")\n",
    "    counties = load_counties()\n",
    "    print(\"Finding raster file paths...\")\n",
    "    livestock_raster_paths = [\n",
    "        str(f) for f in sorted(DATA_DIR.glob(\"*.tif\"))\n",
    "        if \"NLCD\" not in f.name and \"pixel_area\" not in f.name\n",
    "    ]\n",
    "    if not livestock_raster_paths:\n",
    "        print(\"No livestock raster files found. Exiting.\")\n",
    "    else:\n",
    "        print(f\"Found {len(livestock_raster_paths)} livestock rasters.\")\n",
    "        chunk_size = CORES * 2\n",
    "        print(f\"Using a chunk size of {chunk_size} counties.\")\n",
    "        main_processing(livestock_raster_paths, counties, chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3b1e1",
   "metadata": {},
   "source": [
    "Feature Enginnering - core code that creates engineered features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path(\"/content/drive/MyDrive/NewLiv/data\")\n",
    "input_file = DATA_DIR / \"interpolated_livestock_wide.csv\"\n",
    "output_file = DATA_DIR / \"interpolated_livestock_wide_engineered.csv\"\n",
    "\n",
    "# Load the wide-format CSV\n",
    "df = pd.read_csv(input_file, na_values=['', 'NA', '-'])\n",
    "\n",
    "def engineer_features_fast(df):\n",
    "    # Dynamically extract species from column names\n",
    "    area_cols = [col for col in df.columns if col.startswith('area_usable_km2_')]\n",
    "    species = [col.replace('area_usable_km2_', '') for col in area_cols]\n",
    "\n",
    "    # Compute usable_area_percent for each species (vectorized)\n",
    "    # The np.where logic correctly handles division by zero.\n",
    "    for species_name in species:\n",
    "        area_col = f'area_usable_km2_{species_name}'\n",
    "        percent_col = f'usable_area_percent_{species_name}'\n",
    "        if area_col in df.columns and 'total_area_km2' in df.columns:\n",
    "            df[percent_col] = np.where(df['total_area_km2'] != 0, (df[area_col] / df['total_area_km2']) * 100, np.nan)\n",
    "\n",
    "    # Compute growth rates for weighted_mean and head_count (vectorized)\n",
    "    # This replaces the slow loops with a groupby and vectorized pct_change.\n",
    "    df = df.sort_values(by=['GEOID', 'year']).set_index(['GEOID', 'year'])\n",
    "\n",
    "    for species_name in species:\n",
    "        wm_col = f'weighted_mean_{species_name}'\n",
    "        hc_col = f'head_count_{species_name}'\n",
    "\n",
    "        # Calculate percent change grouped by GEOID\n",
    "        if wm_col in df.columns:\n",
    "            df[f'growth_rate_wm_{species_name}'] = df.groupby(level='GEOID')[wm_col].pct_change().mul(100)\n",
    "\n",
    "        if hc_col in df.columns:\n",
    "            df[f'growth_rate_hc_{species_name}'] = df.groupby(level='GEOID')[hc_col].pct_change().mul(100)\n",
    "\n",
    "    # Compute aggregated features (vectorized)\n",
    "    # Sum and mean are already vectorized functions in pandas.\n",
    "    wm_cols = [f'weighted_mean_{s}' for s in species if f'weighted_mean_{s}' in df.columns]\n",
    "    hc_cols = [f'head_count_{s}' for s in species if f'head_count_{s}' in df.columns]\n",
    "\n",
    "    if wm_cols:\n",
    "        df['total_weighted_mean'] = df[wm_cols].sum(axis=1)\n",
    "        df['avg_weighted_mean'] = df[wm_cols].mean(axis=1)\n",
    "\n",
    "    if hc_cols:\n",
    "        df['total_head_count'] = df[hc_cols].sum(axis=1)\n",
    "\n",
    "    return df.reset_index()\n",
    "\n",
    "# Apply the fast feature engineering\n",
    "engineered_df = engineer_features_fast(df.copy()) # Use a copy to avoid chained assignment warnings\n",
    "\n",
    "# Save the result\n",
    "engineered_df.to_csv(output_file, index=False)\n",
    "print(f\"Engineered features saved to {output_file} at {datetime.now().strftime('%I:%M %p CDT on %B %d, %Y')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a9a16",
   "metadata": {},
   "source": [
    "Livestock datset Interpolation code - using the datasets from 2010, 2015, 2020, we create a dataset to match our LE temporal resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b071c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path(\"/content/drive/MyDrive/NewLiv/data\")\n",
    "input_file = DATA_DIR / \"combined_livestock_stats.csv\"\n",
    "output_file = DATA_DIR / \"interpolated_livestock_wide.csv\"\n",
    "county_shp = DATA_DIR / \"cb_2023_us_county_500k.shp\"\n",
    "\n",
    "# Load county data for total area\n",
    "counties_gdf = gpd.read_file(county_shp)\n",
    "counties_gdf = counties_gdf[[\"GEOID\", \"ALAND\", \"AWATER\"]].copy()\n",
    "\n",
    "# --- FIX: Standardize GEOID in shapefile data to a 5-digit string ---\n",
    "counties_gdf[\"GEOID\"] = counties_gdf[\"GEOID\"].astype(str).str.zfill(5)\n",
    "\n",
    "counties_gdf[\"total_area_km2\"] = (counties_gdf[\"ALAND\"] + counties_gdf[\"AWATER\"]) / 1e6\n",
    "counties_gdf = counties_gdf.drop(columns=[\"ALAND\", \"AWATER\"])\n",
    "county_area_map = counties_gdf.set_index('GEOID')['total_area_km2'].to_dict()\n",
    "\n",
    "# Load the combined CSV\n",
    "df = pd.read_csv(input_file, na_values=['', 'NA', '-'])\n",
    "\n",
    "# --- FIX: Standardize GEOID in the CSV data to a 5-digit string ---\n",
    "df[\"GEOID\"] = df[\"GEOID\"].astype(str).str.zfill(5)\n",
    "\n",
    "# Define the year range for interpolation\n",
    "start_year = 2003\n",
    "end_year = 2020\n",
    "years = range(start_year, end_year + 1)\n",
    "\n",
    "# Function to interpolate values for a given GEOID and species\n",
    "def interpolate_group(group):\n",
    "    full_index = pd.Index(years, name='year')\n",
    "    full_df = group.set_index('year').reindex(full_index)\n",
    "\n",
    "    full_df['GEOID'] = group['GEOID'].iloc[0]\n",
    "    full_df['species'] = group['species'].iloc[0]\n",
    "\n",
    "    if 'area_usable_km2' in group.columns and not group['area_usable_km2'].empty:\n",
    "        full_df['area_usable_km2'] = group['area_usable_km2'].iloc[0]\n",
    "\n",
    "    cols_to_interpolate = ['weighted_mean', 'std_dev', 'std_error', 'head_count']\n",
    "\n",
    "    for col in cols_to_interpolate:\n",
    "        if col in full_df.columns:\n",
    "            if 2010 in full_df.index and not pd.isna(full_df.loc[2010, col]):\n",
    "                val_2010 = full_df.loc[2010, col]\n",
    "                full_df.loc[start_year:2010, col] = full_df.loc[start_year:2010, col].fillna(val_2010)\n",
    "\n",
    "            full_df[col] = full_df[col].interpolate(method='linear', limit_area='inside')\n",
    "\n",
    "    return full_df.reset_index()\n",
    "\n",
    "# Step 1: Perform interpolation on the long-format data\n",
    "interpolated_long_df = df.groupby(['GEOID', 'species'], group_keys=False).apply(interpolate_group).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Pivot the interpolated data to achieve the wide format\n",
    "interpolated_wide_df = interpolated_long_df.pivot_table(\n",
    "    index=['GEOID', 'year'],\n",
    "    columns='species',\n",
    "    values=['weighted_mean', 'std_dev', 'std_error', 'head_count', 'area_usable_km2']\n",
    ").reset_index()\n",
    "\n",
    "# Step 3: Flatten the multi-level columns\n",
    "interpolated_wide_df.columns = [f'{col[0]}_{col[1]}' if col[0] in ['weighted_mean', 'std_dev', 'std_error', 'head_count', 'area_usable_km2'] else col[0] for col in interpolated_wide_df.columns]\n",
    "\n",
    "# Step 4: Add the total_area_km2 column to the wide DataFrame\n",
    "# This will now work correctly after standardizing the GEOID columns\n",
    "interpolated_wide_df['total_area_km2'] = interpolated_wide_df['GEOID'].map(county_area_map)\n",
    "\n",
    "# Reorder columns for readability\n",
    "cols = ['GEOID', 'year', 'total_area_km2'] + [col for col in interpolated_wide_df.columns if col not in ['GEOID', 'year', 'total_area_km2']]\n",
    "interpolated_wide_df = interpolated_wide_df[cols]\n",
    "\n",
    "# Save the final result\n",
    "interpolated_wide_df.to_csv(output_file, index=False)\n",
    "print(f\"Interpolated wide-format data saved to {output_file} at {datetime.now().strftime('%I:%M %p CDT on %B %d, %Y')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ddcae",
   "metadata": {},
   "source": [
    "Next two code boloks combines the  a) livestock dataset merge b) LE and Livestock datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1634cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined dataset ready for ML/DL: /Users/faizahmad/Desktop/NewLiv/data/combined_final_livestock_wide_engineered_with_LifeEx.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DATA_DIR      = Path(\"/Users/faizahmad/Desktop/NewLiv/data/\")\n",
    "LIFEEX_CSV    = DATA_DIR / \"final_dataset_103_features 1.csv\"\n",
    "LIV_PREPPED   = DATA_DIR / \"interpolated_livestock_wide_engineered.csv\"\n",
    "OUTPUT_CSV    = DATA_DIR / \"combined_final_livestock_wide_engineered_with_LifeEx.csv\"\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# 1Ô∏è‚É£  Load LifeEX (ensure fips is string, zero‚Äëpadded)\n",
    "lifeex = pd.read_csv(LIFEEX_CSV, dtype={\"fips\": str})\n",
    "lifeex[\"fips\"] = lifeex[\"fips\"].str.zfill(5)\n",
    "lifeex[\"year\"] = lifeex[\"year\"].astype(int)\n",
    "\n",
    "# 2Ô∏è‚É£  Load livestock (rename GEOID ‚Üí fips, zero‚Äëpad)\n",
    "liv = pd.read_csv(LIV_PREPPED, dtype={\"GEOID\": str})\n",
    "liv[\"GEOID\"] = liv[\"GEOID\"].str.zfill(5)\n",
    "liv = liv.rename(columns={\"GEOID\": \"fips\"})\n",
    "liv[\"year\"]  = liv[\"year\"].astype(int)\n",
    "\n",
    "# 3Ô∏è‚É£  Full outer join on fips & year\n",
    "combined = pd.merge(\n",
    "    lifeex,\n",
    "    liv,\n",
    "    on=[\"fips\", \"year\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£  Save final dataset\n",
    "combined.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"‚úÖ Combined dataset ready for ML/DL:\", OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d1ffb",
   "metadata": {},
   "source": [
    "A total of 95 columns in our combined file before multi-colinearity cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523318d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fips  year  MeanLifeExpectency  count_buffalo  count_cattle  count_chicken  \\\n",
      "0  1001  2003           74.628765           35.0          35.0           35.0   \n",
      "1  1003  2003           76.661419           76.0          76.0           76.0   \n",
      "2  1005  2003           74.047811           47.0          47.0           47.0   \n",
      "3  1007  2003           73.057987           34.0          34.0           34.0   \n",
      "4  1009  2003           75.053119           40.0          40.0           40.0   \n",
      "\n",
      "   count_duck  count_goat  count_horse  count_pig  ...  growth_rate_hc_goat  \\\n",
      "0        35.0        35.0         35.0       35.0  ...                  NaN   \n",
      "1        76.0        76.0         76.0       76.0  ...                  NaN   \n",
      "2        47.0        47.0         47.0       47.0  ...                  NaN   \n",
      "3        34.0        34.0         34.0       34.0  ...                  NaN   \n",
      "4        40.0        40.0         40.0       40.0  ...                  NaN   \n",
      "\n",
      "   growth_rate_wm_horse  growth_rate_hc_horse  growth_rate_wm_pig  \\\n",
      "0                   NaN                   NaN                 NaN   \n",
      "1                   NaN                   NaN                 NaN   \n",
      "2                   NaN                   NaN                 NaN   \n",
      "3                   NaN                   NaN                 NaN   \n",
      "4                   NaN                   NaN                 NaN   \n",
      "\n",
      "   growth_rate_hc_pig  growth_rate_wm_sheep  growth_rate_hc_sheep  \\\n",
      "0                 NaN                   NaN                   NaN   \n",
      "1                 NaN                   NaN                   NaN   \n",
      "2                 NaN                   NaN                   NaN   \n",
      "3                 NaN                   NaN                   NaN   \n",
      "4                 NaN                   NaN                   NaN   \n",
      "\n",
      "   total_weighted_mean  avg_weighted_mean  total_head_count  \n",
      "0          2480.318850         310.039856      1.417783e+06  \n",
      "1           443.843570          55.480446      6.487983e+05  \n",
      "2        103634.124689       12954.265586      9.287887e+07  \n",
      "3          3053.988500         381.748562      9.033280e+05  \n",
      "4        437630.015054       54703.751882      5.764284e+08  \n",
      "\n",
      "[5 rows x 95 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52161 entries, 0 to 52160\n",
      "Data columns (total 95 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   fips                         52161 non-null  int64  \n",
      " 1   year                         52161 non-null  int64  \n",
      " 2   MeanLifeExpectency           52161 non-null  float64\n",
      " 3   count_buffalo                52161 non-null  float64\n",
      " 4   count_cattle                 52161 non-null  float64\n",
      " 5   count_chicken                52161 non-null  float64\n",
      " 6   count_duck                   52161 non-null  float64\n",
      " 7   count_goat                   52161 non-null  float64\n",
      " 8   count_horse                  52161 non-null  float64\n",
      " 9   count_pig                    52161 non-null  float64\n",
      " 10  count_sheep                  52161 non-null  float64\n",
      " 11  mean_buffalo                 52161 non-null  float64\n",
      " 12  mean_cattle                  52161 non-null  float64\n",
      " 13  mean_chicken                 52161 non-null  float64\n",
      " 14  mean_duck                    52161 non-null  float64\n",
      " 15  mean_goat                    52161 non-null  float64\n",
      " 16  mean_horse                   52161 non-null  float64\n",
      " 17  mean_pig                     52161 non-null  float64\n",
      " 18  mean_sheep                   52161 non-null  float64\n",
      " 19  sum_buffalo                  52161 non-null  float64\n",
      " 20  sum_cattle                   52161 non-null  float64\n",
      " 21  sum_chicken                  52161 non-null  float64\n",
      " 22  sum_duck                     52161 non-null  float64\n",
      " 23  sum_goat                     52161 non-null  float64\n",
      " 24  sum_horse                    52161 non-null  float64\n",
      " 25  sum_pig                      52161 non-null  float64\n",
      " 26  sum_sheep                    52161 non-null  float64\n",
      " 27  total_area_km2               52161 non-null  float64\n",
      " 28  area_usable_km2_buffalo      52161 non-null  float64\n",
      " 29  area_usable_km2_cattle       52161 non-null  float64\n",
      " 30  area_usable_km2_chicken      52161 non-null  float64\n",
      " 31  area_usable_km2_duck         52161 non-null  float64\n",
      " 32  area_usable_km2_goat         52161 non-null  float64\n",
      " 33  area_usable_km2_horse        52161 non-null  float64\n",
      " 34  area_usable_km2_pig          52161 non-null  float64\n",
      " 35  area_usable_km2_sheep        52161 non-null  float64\n",
      " 36  head_count_buffalo           24949 non-null  float64\n",
      " 37  head_count_cattle            52161 non-null  float64\n",
      " 38  head_count_chicken           52161 non-null  float64\n",
      " 39  head_count_duck              39885 non-null  float64\n",
      " 40  head_count_goat              52161 non-null  float64\n",
      " 41  head_count_horse             39885 non-null  float64\n",
      " 42  head_count_pig               52161 non-null  float64\n",
      " 43  head_count_sheep             52161 non-null  float64\n",
      " 44  std_dev_buffalo              24949 non-null  float64\n",
      " 45  std_dev_cattle               52161 non-null  float64\n",
      " 46  std_dev_chicken              52161 non-null  float64\n",
      " 47  std_dev_duck                 39885 non-null  float64\n",
      " 48  std_dev_goat                 52161 non-null  float64\n",
      " 49  std_dev_horse                39885 non-null  float64\n",
      " 50  std_dev_pig                  52161 non-null  float64\n",
      " 51  std_dev_sheep                52161 non-null  float64\n",
      " 52  std_error_buffalo            24949 non-null  float64\n",
      " 53  std_error_cattle             52161 non-null  float64\n",
      " 54  std_error_chicken            52161 non-null  float64\n",
      " 55  std_error_duck               39885 non-null  float64\n",
      " 56  std_error_goat               52161 non-null  float64\n",
      " 57  std_error_horse              39885 non-null  float64\n",
      " 58  std_error_pig                52161 non-null  float64\n",
      " 59  std_error_sheep              52161 non-null  float64\n",
      " 60  weighted_mean_buffalo        24949 non-null  float64\n",
      " 61  weighted_mean_cattle         52161 non-null  float64\n",
      " 62  weighted_mean_chicken        52161 non-null  float64\n",
      " 63  weighted_mean_duck           39885 non-null  float64\n",
      " 64  weighted_mean_goat           52161 non-null  float64\n",
      " 65  weighted_mean_horse          39885 non-null  float64\n",
      " 66  weighted_mean_pig            52161 non-null  float64\n",
      " 67  weighted_mean_sheep          52161 non-null  float64\n",
      " 68  usable_area_percent_buffalo  52161 non-null  float64\n",
      " 69  usable_area_percent_cattle   52161 non-null  float64\n",
      " 70  usable_area_percent_chicken  52161 non-null  float64\n",
      " 71  usable_area_percent_duck     52161 non-null  float64\n",
      " 72  usable_area_percent_goat     52161 non-null  float64\n",
      " 73  usable_area_percent_horse    52161 non-null  float64\n",
      " 74  usable_area_percent_pig      52161 non-null  float64\n",
      " 75  usable_area_percent_sheep    52161 non-null  float64\n",
      " 76  growth_rate_wm_buffalo       37761 non-null  float64\n",
      " 77  growth_rate_hc_buffalo       37761 non-null  float64\n",
      " 78  growth_rate_wm_cattle        49077 non-null  float64\n",
      " 79  growth_rate_hc_cattle        49077 non-null  float64\n",
      " 80  growth_rate_wm_chicken       49059 non-null  float64\n",
      " 81  growth_rate_hc_chicken       49059 non-null  float64\n",
      " 82  growth_rate_wm_duck          49041 non-null  float64\n",
      " 83  growth_rate_hc_duck          49041 non-null  float64\n",
      " 84  growth_rate_wm_goat          49066 non-null  float64\n",
      " 85  growth_rate_hc_goat          49066 non-null  float64\n",
      " 86  growth_rate_wm_horse         49077 non-null  float64\n",
      " 87  growth_rate_hc_horse         49077 non-null  float64\n",
      " 88  growth_rate_wm_pig           49073 non-null  float64\n",
      " 89  growth_rate_hc_pig           49073 non-null  float64\n",
      " 90  growth_rate_wm_sheep         49073 non-null  float64\n",
      " 91  growth_rate_hc_sheep         49073 non-null  float64\n",
      " 92  total_weighted_mean          52161 non-null  float64\n",
      " 93  avg_weighted_mean            52161 non-null  float64\n",
      " 94  total_head_count             52161 non-null  float64\n",
      "dtypes: float64(93), int64(2)\n",
      "memory usage: 37.8 MB\n",
      "None\n",
      "               fips          year  MeanLifeExpectency  count_buffalo  \\\n",
      "count  52161.000000  52161.000000        52161.000000   52161.000000   \n",
      "mean   30698.001495   2011.000575           77.169712      30.923889   \n",
      "std    14988.319773      4.899163            2.448107      49.011731   \n",
      "min     1001.000000   2003.000000           65.176273       0.000000   \n",
      "25%    19049.000000   2007.000000           75.492520       0.000000   \n",
      "50%    29197.000000   2011.000000           77.276202      22.200000   \n",
      "75%    46011.000000   2015.000000           78.838345      39.000000   \n",
      "max    56045.000000   2019.000000           92.253858     807.000000   \n",
      "\n",
      "       count_cattle  count_chicken   count_duck    count_goat   count_horse  \\\n",
      "count  52161.000000   52161.000000  52161.00000  52161.000000  52161.000000   \n",
      "mean      52.464485      52.448419     52.46276     52.464485     52.464485   \n",
      "std       58.658653      58.644540     58.65480     58.658653     58.658653   \n",
      "min        1.000000       1.000000      1.00000      1.000000      1.000000   \n",
      "25%       28.000000      28.000000     28.00000     28.000000     28.000000   \n",
      "50%       37.000000      37.000000     37.00000     37.000000     37.000000   \n",
      "75%       51.000000      51.000000     51.00000     51.000000     51.000000   \n",
      "max      807.000000     807.000000    807.00000    807.000000    807.000000   \n",
      "\n",
      "          count_pig  ...  growth_rate_hc_goat  growth_rate_wm_horse  \\\n",
      "count  52161.000000  ...          49066.00000          49077.000000   \n",
      "mean      52.448419  ...                  inf              0.873903   \n",
      "std       58.644540  ...                  NaN              5.000939   \n",
      "min        1.000000  ...           -100.00000            -79.151099   \n",
      "25%       28.000000  ...            -19.68233              0.000000   \n",
      "50%       37.000000  ...              0.00000              0.000000   \n",
      "75%       51.000000  ...              0.00000              0.000000   \n",
      "max      807.000000  ...                  inf            320.311655   \n",
      "\n",
      "       growth_rate_hc_horse  growth_rate_wm_pig  growth_rate_hc_pig  \\\n",
      "count          49077.000000        49073.000000        49073.000000   \n",
      "mean               0.873903           -1.364060           -1.364060   \n",
      "std                5.000939          220.542879          220.542879   \n",
      "min              -79.151099         -100.000000         -100.000000   \n",
      "25%                0.000000          -19.651637          -19.651637   \n",
      "50%                0.000000            0.000000            0.000000   \n",
      "75%                0.000000            0.000000            0.000000   \n",
      "max              320.311655        38414.550465        38414.550465   \n",
      "\n",
      "       growth_rate_wm_sheep  growth_rate_hc_sheep  total_weighted_mean  \\\n",
      "count          49073.000000          49073.000000         5.216100e+04   \n",
      "mean              -6.855542             -6.855542         2.880706e+04   \n",
      "std               19.439326             19.439326         9.724186e+04   \n",
      "min             -100.000000           -100.000000         0.000000e+00   \n",
      "25%              -19.691396            -19.691396         6.380027e+02   \n",
      "50%                0.000000              0.000000         1.829913e+03   \n",
      "75%                0.000000              0.000000         8.113604e+03   \n",
      "max             1288.486818           1288.486818         1.851010e+06   \n",
      "\n",
      "       avg_weighted_mean  total_head_count  \n",
      "count       52161.000000      5.216100e+04  \n",
      "mean         4076.933676      2.151622e+07  \n",
      "std         13492.040858      7.628887e+07  \n",
      "min             0.000000      0.000000e+00  \n",
      "25%            92.184826      3.946654e+05  \n",
      "50%           258.209816      2.121488e+06  \n",
      "75%          1194.511726      8.085978e+06  \n",
      "max        271856.935942      1.537556e+09  \n",
      "\n",
      "[8 rows x 95 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizahmad/miniforge3/envs/geo_ml/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/faizahmad/miniforge3/envs/geo_ml/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/faizahmad/miniforge3/envs/geo_ml/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/faizahmad/miniforge3/envs/geo_ml/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df3=pd.read_csv('/Users/faizahmad/Desktop/grok_live/combined_fina_2_df_Live_life_fixed.csv')\n",
    "print(df3.head())\n",
    "print(df3.info())\n",
    "print(df3.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda522ac",
   "metadata": {},
   "source": [
    "b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c1efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined dataset ready for ML/DL: /Users/faizahmad/Desktop/NewLiv/data/combined_fina_2_df_Live_life.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DATA_DIR      = Path(\"/Users/faizahmad/Desktop/NewLiv/data/\")\n",
    "LIFEEX_CSV    = DATA_DIR / \"df_livestock_with_counts.csv\"\n",
    "LIV_PREPPED   = DATA_DIR / \"ML ready livestock_engineered_lifeexpectancy_final_df.csv\"\n",
    "OUTPUT_CSV    = DATA_DIR / \"combined_fina_2_df_Live_life.csv\"\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# 1Ô∏è‚É£  Load LifeEX (ensure fips is string, zero‚Äëpadded)\n",
    "lifeex = pd.read_csv(LIFEEX_CSV, dtype={\"fips\": str})\n",
    "lifeex[\"fips\"] = lifeex[\"fips\"].str.zfill(5)\n",
    "lifeex[\"year\"] = lifeex[\"year\"].astype(int)\n",
    "\n",
    "# 2Ô∏è‚É£  Load livestock (rename GEOID ‚Üí fips, zero‚Äëpad)\n",
    "liv = pd.read_csv(LIV_PREPPED, dtype={\"fips\": str})\n",
    "liv[\"fips\"] = liv[\"fips\"].str.zfill(5)\n",
    "liv[\"year\"]  = liv[\"year\"].astype(int)\n",
    "\n",
    "# 3Ô∏è‚É£  Full outer join on fips & year\n",
    "combined = pd.merge(\n",
    "    lifeex,\n",
    "    liv,\n",
    "    on=[\"fips\", \"year\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£  Save final dataset\n",
    "combined.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"‚úÖ Combined dataset ready for ML/DL:\", OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cd405",
   "metadata": {},
   "source": [
    "Feature dropping for robust ML - this generates our cleanned df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"/Users/faizahmad/Desktop/grok_live/ML ready livestock_engineered_lifeexpectancy_final_df.csv\")\n",
    "\n",
    "# Remove duplicate MeanLifeExpectency columns\n",
    "life_cols = [col for col in df.columns if \"MeanLifeExpectency\" in col]\n",
    "if len(life_cols) > 1:\n",
    "    df = df.drop(columns=life_cols[1:])\n",
    "df = df.rename(columns={life_cols[0]: \"MeanLifeExpectency\"})\n",
    "\n",
    "# Exclude target and identifiers\n",
    "features = df.drop(columns=['fips', 'year', 'MeanLifeExpectency'])\n",
    "\n",
    "# Identify features to drop\n",
    "missing = features.isnull().mean()\n",
    "high_missing = missing[missing > 0.3].index.tolist()\n",
    "\n",
    "low_variance = features.loc[:, features.nunique() <= 1].columns.tolist()\n",
    "\n",
    "corr_matrix = features.corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.95)]\n",
    "\n",
    "# Combine and drop\n",
    "features_to_drop = set(high_missing + low_variance + high_corr)\n",
    "df_cleaned = df.drop(columns=features_to_drop)\n",
    "\n",
    "# Save cleaned file\n",
    "df_cleaned.to_csv(\"cleaned_combined_life_df.csv\", index=False)\n",
    "\n",
    "# Optional: Save dropped columns with reasons\n",
    "dropped = pd.DataFrame({'Feature': list(features_to_drop)})\n",
    "dropped['Reason'] = dropped['Feature'].apply(\n",
    "    lambda x: 'High Missingness (>30%)' if x in high_missing else (\n",
    "        'Low Variance' if x in low_variance else 'Highly Correlated (>0.95)'\n",
    "    )\n",
    ")\n",
    "dropped.to_csv(\"dropped_features_with_reasons.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca32a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/faizahmad/Desktop/grok_live/cleaned_combined_life_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f073e5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>year</th>\n",
       "      <th>MeanLifeExpectency</th>\n",
       "      <th>count_buffalo</th>\n",
       "      <th>count_cattle</th>\n",
       "      <th>mean_buffalo</th>\n",
       "      <th>mean_cattle</th>\n",
       "      <th>mean_chicken</th>\n",
       "      <th>mean_duck</th>\n",
       "      <th>mean_goat</th>\n",
       "      <th>...</th>\n",
       "      <th>std_error_sheep</th>\n",
       "      <th>usable_area_percent_buffalo</th>\n",
       "      <th>growth_rate_wm_buffalo</th>\n",
       "      <th>growth_rate_wm_cattle</th>\n",
       "      <th>growth_rate_wm_chicken</th>\n",
       "      <th>growth_rate_wm_duck</th>\n",
       "      <th>growth_rate_wm_goat</th>\n",
       "      <th>growth_rate_wm_horse</th>\n",
       "      <th>growth_rate_wm_pig</th>\n",
       "      <th>growth_rate_wm_sheep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>2003</td>\n",
       "      <td>74.628765</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>65.904788</td>\n",
       "      <td>860.999684</td>\n",
       "      <td>1423.557155</td>\n",
       "      <td>8.388511</td>\n",
       "      <td>41.508960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671143</td>\n",
       "      <td>36.517602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01003</td>\n",
       "      <td>2003</td>\n",
       "      <td>76.661419</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.835759</td>\n",
       "      <td>28.862582</td>\n",
       "      <td>2.434907</td>\n",
       "      <td>24.505563</td>\n",
       "      <td>...</td>\n",
       "      <td>1.197483</td>\n",
       "      <td>27.840037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01005</td>\n",
       "      <td>2003</td>\n",
       "      <td>74.047811</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.621798</td>\n",
       "      <td>512.685904</td>\n",
       "      <td>103001.408125</td>\n",
       "      <td>9.907964</td>\n",
       "      <td>16.115635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515592</td>\n",
       "      <td>38.256086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01007</td>\n",
       "      <td>2003</td>\n",
       "      <td>73.057987</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.848961</td>\n",
       "      <td>307.661134</td>\n",
       "      <td>2677.674651</td>\n",
       "      <td>2.071313</td>\n",
       "      <td>16.036272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559568</td>\n",
       "      <td>18.238589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01009</td>\n",
       "      <td>2003</td>\n",
       "      <td>75.053119</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.794029</td>\n",
       "      <td>1477.174746</td>\n",
       "      <td>435816.552930</td>\n",
       "      <td>12.237306</td>\n",
       "      <td>56.636708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753218</td>\n",
       "      <td>78.164150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52156</th>\n",
       "      <td>56037</td>\n",
       "      <td>2019</td>\n",
       "      <td>78.018892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.588964</td>\n",
       "      <td>13.908474</td>\n",
       "      <td>0.290212</td>\n",
       "      <td>0.051913</td>\n",
       "      <td>1.800577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200563</td>\n",
       "      <td>0.954676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.028656</td>\n",
       "      <td>-48.467522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.261210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.879305</td>\n",
       "      <td>-48.183869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52157</th>\n",
       "      <td>56039</td>\n",
       "      <td>2019</td>\n",
       "      <td>85.638149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.187142</td>\n",
       "      <td>4.416270</td>\n",
       "      <td>0.289818</td>\n",
       "      <td>4.623372</td>\n",
       "      <td>0.053630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140562</td>\n",
       "      <td>6.903559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.880597</td>\n",
       "      <td>-48.476390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.020152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.504697</td>\n",
       "      <td>-48.061876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52158</th>\n",
       "      <td>56041</td>\n",
       "      <td>2019</td>\n",
       "      <td>77.521691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.209951</td>\n",
       "      <td>84.895367</td>\n",
       "      <td>2.530504</td>\n",
       "      <td>0.752106</td>\n",
       "      <td>1.614481</td>\n",
       "      <td>...</td>\n",
       "      <td>2.751675</td>\n",
       "      <td>6.837231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.018224</td>\n",
       "      <td>-48.526783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.109447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.778035</td>\n",
       "      <td>-48.146817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52159</th>\n",
       "      <td>56043</td>\n",
       "      <td>2019</td>\n",
       "      <td>78.137158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.669329</td>\n",
       "      <td>62.097799</td>\n",
       "      <td>2.385102</td>\n",
       "      <td>6.604897</td>\n",
       "      <td>1.493581</td>\n",
       "      <td>...</td>\n",
       "      <td>1.848628</td>\n",
       "      <td>16.175882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.934240</td>\n",
       "      <td>-48.503145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.014093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.819189</td>\n",
       "      <td>-48.067461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52160</th>\n",
       "      <td>56045</td>\n",
       "      <td>2019</td>\n",
       "      <td>79.189934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.672429</td>\n",
       "      <td>88.874505</td>\n",
       "      <td>2.112673</td>\n",
       "      <td>3.313545</td>\n",
       "      <td>0.297738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621755</td>\n",
       "      <td>66.745481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.930071</td>\n",
       "      <td>-48.462125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.004493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.774474</td>\n",
       "      <td>-48.034394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52161 rows √ó 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fips  year  MeanLifeExpectency  count_buffalo  count_cattle  \\\n",
       "0      01001  2003           74.628765           35.0          35.0   \n",
       "1      01003  2003           76.661419           76.0          76.0   \n",
       "2      01005  2003           74.047811           47.0          47.0   \n",
       "3      01007  2003           73.057987           34.0          34.0   \n",
       "4      01009  2003           75.053119           40.0          40.0   \n",
       "...      ...   ...                 ...            ...           ...   \n",
       "52156  56037  2019           78.018892            0.0         471.0   \n",
       "52157  56039  2019           85.638149            0.0         202.0   \n",
       "52158  56041  2019           77.521691            0.0         104.0   \n",
       "52159  56043  2019           78.137158            0.0         127.0   \n",
       "52160  56045  2019           79.189934            0.0         120.0   \n",
       "\n",
       "       mean_buffalo  mean_cattle   mean_chicken  mean_duck  mean_goat  ...  \\\n",
       "0         65.904788   860.999684    1423.557155   8.388511  41.508960  ...   \n",
       "1          0.000000   311.835759      28.862582   2.434907  24.505563  ...   \n",
       "2         53.621798   512.685904  103001.408125   9.907964  16.115635  ...   \n",
       "3         14.848961   307.661134    2677.674651   2.071313  16.036272  ...   \n",
       "4         25.794029  1477.174746  435816.552930  12.237306  56.636708  ...   \n",
       "...             ...          ...            ...        ...        ...  ...   \n",
       "52156      0.588964    13.908474       0.290212   0.051913   1.800577  ...   \n",
       "52157      0.187142     4.416270       0.289818   4.623372   0.053630  ...   \n",
       "52158      1.209951    84.895367       2.530504   0.752106   1.614481  ...   \n",
       "52159      1.669329    62.097799       2.385102   6.604897   1.493581  ...   \n",
       "52160      1.672429    88.874505       2.112673   3.313545   0.297738  ...   \n",
       "\n",
       "       std_error_sheep  usable_area_percent_buffalo  growth_rate_wm_buffalo  \\\n",
       "0             0.671143                    36.517602                     NaN   \n",
       "1             1.197483                    27.840037                     NaN   \n",
       "2             0.515592                    38.256086                     NaN   \n",
       "3             0.559568                    18.238589                     NaN   \n",
       "4             0.753218                    78.164150                     NaN   \n",
       "...                ...                          ...                     ...   \n",
       "52156         0.200563                     0.954676                     0.0   \n",
       "52157         0.140562                     6.903559                     0.0   \n",
       "52158         2.751675                     6.837231                     0.0   \n",
       "52159         1.848628                    16.175882                     0.0   \n",
       "52160         0.621755                    66.745481                     0.0   \n",
       "\n",
       "       growth_rate_wm_cattle  growth_rate_wm_chicken  growth_rate_wm_duck  \\\n",
       "0                        NaN                     NaN                  NaN   \n",
       "1                        NaN                     NaN                  NaN   \n",
       "2                        NaN                     NaN                  NaN   \n",
       "3                        NaN                     NaN                  NaN   \n",
       "4                        NaN                     NaN                  NaN   \n",
       "...                      ...                     ...                  ...   \n",
       "52156             -48.028656              -48.467522                  0.0   \n",
       "52157             -47.880597              -48.476390                  0.0   \n",
       "52158             -48.018224              -48.526783                  0.0   \n",
       "52159             -47.934240              -48.503145                  0.0   \n",
       "52160             -47.930071              -48.462125                  0.0   \n",
       "\n",
       "       growth_rate_wm_goat  growth_rate_wm_horse  growth_rate_wm_pig  \\\n",
       "0                      NaN                   NaN                 NaN   \n",
       "1                      NaN                   NaN                 NaN   \n",
       "2                      NaN                   NaN                 NaN   \n",
       "3                      NaN                   NaN                 NaN   \n",
       "4                      NaN                   NaN                 NaN   \n",
       "...                    ...                   ...                 ...   \n",
       "52156           -48.261210                   0.0          -47.879305   \n",
       "52157           -48.020152                   0.0          -47.504697   \n",
       "52158           -48.109447                   0.0          -47.778035   \n",
       "52159           -48.014093                   0.0          -47.819189   \n",
       "52160           -48.004493                   0.0          -47.774474   \n",
       "\n",
       "       growth_rate_wm_sheep  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "...                     ...  \n",
       "52156            -48.183869  \n",
       "52157            -48.061876  \n",
       "52158            -48.146817  \n",
       "52159            -48.067461  \n",
       "52160            -48.034394  \n",
       "\n",
       "[52161 rows x 45 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8da4afa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics:\n",
      "               year  MeanLifeExpectency  count_buffalo  count_cattle  \\\n",
      "count  52161.000000        52161.000000   52161.000000  52161.000000   \n",
      "mean    2011.000575           77.169712      30.923889     52.464485   \n",
      "std        4.899163            2.448107      49.011731     58.658653   \n",
      "min     2003.000000           65.176273       0.000000      1.000000   \n",
      "25%     2007.000000           75.492520       0.000000     28.000000   \n",
      "50%     2011.000000           77.276202      22.200000     37.000000   \n",
      "75%     2015.000000           78.838345      39.000000     51.000000   \n",
      "max     2019.000000           92.253858     807.000000    807.000000   \n",
      "\n",
      "       mean_buffalo   mean_cattle  mean_chicken     mean_duck     mean_goat  \\\n",
      "count  52161.000000  52161.000000  5.216100e+04  52161.000000  52161.000000   \n",
      "mean      10.069839    838.721267  2.695304e+04    104.060398     28.142092   \n",
      "std       27.137042    991.635482  9.691533e+04   1776.773154     48.940265   \n",
      "min        0.000000      0.000000  0.000000e+00      0.000000      0.000000   \n",
      "25%        0.196721    214.139956  3.275954e+01      4.382154      7.166901   \n",
      "50%        3.020142    519.385111  1.629576e+02      8.730771     16.924074   \n",
      "75%       10.431255   1134.825372  4.066490e+03     15.134224     33.024267   \n",
      "max      562.578468  15315.973484  1.848398e+06  81430.877165   1018.057778   \n",
      "\n",
      "         mean_horse  ...  std_error_sheep  usable_area_percent_buffalo  \\\n",
      "count  52161.000000  ...     52161.000000                 52161.000000   \n",
      "mean     121.303124  ...         3.228628                    54.677942   \n",
      "std      168.814460  ...         7.853096                    35.257718   \n",
      "min        0.000000  ...         0.000000                     0.062536   \n",
      "25%       38.433413  ...         0.840521                    23.396296   \n",
      "50%       79.739922  ...         1.631552                    51.298075   \n",
      "75%      151.756091  ...         3.248911                    85.797493   \n",
      "max     3741.274794  ...       257.977268                   147.895848   \n",
      "\n",
      "       growth_rate_wm_buffalo  growth_rate_wm_cattle  growth_rate_wm_chicken  \\\n",
      "count            37761.000000           49077.000000            4.905900e+04   \n",
      "mean                -0.254179              -7.987779                     inf   \n",
      "std                  3.948333              20.670653                     NaN   \n",
      "min               -100.000000             -83.612126           -1.000000e+02   \n",
      "25%                  0.000000             -19.635407           -1.975901e+01   \n",
      "50%                  0.000000               0.000000            0.000000e+00   \n",
      "75%                  0.000000               0.000000            0.000000e+00   \n",
      "max                 17.639810            3162.951698                     inf   \n",
      "\n",
      "       growth_rate_wm_duck  growth_rate_wm_goat  growth_rate_wm_horse  \\\n",
      "count         49041.000000          49066.00000          49077.000000   \n",
      "mean              4.034818                  inf              0.873903   \n",
      "std              62.840554                  NaN              5.000939   \n",
      "min            -100.000000           -100.00000            -79.151099   \n",
      "25%               0.000000            -19.68233              0.000000   \n",
      "50%               0.000000              0.00000              0.000000   \n",
      "75%               0.000000              0.00000              0.000000   \n",
      "max            9413.475178                  inf            320.311655   \n",
      "\n",
      "       growth_rate_wm_pig  growth_rate_wm_sheep  \n",
      "count        49073.000000          49073.000000  \n",
      "mean            -1.364060             -6.855542  \n",
      "std            220.542879             19.439326  \n",
      "min           -100.000000           -100.000000  \n",
      "25%            -19.651637            -19.691396  \n",
      "50%              0.000000              0.000000  \n",
      "75%              0.000000              0.000000  \n",
      "max          38414.550465           1288.486818  \n",
      "\n",
      "[8 rows x 44 columns]\n",
      "\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52161 entries, 0 to 52160\n",
      "Data columns (total 45 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   fips                         52161 non-null  object \n",
      " 1   year                         52161 non-null  int64  \n",
      " 2   MeanLifeExpectency           52161 non-null  float64\n",
      " 3   count_buffalo                52161 non-null  float64\n",
      " 4   count_cattle                 52161 non-null  float64\n",
      " 5   mean_buffalo                 52161 non-null  float64\n",
      " 6   mean_cattle                  52161 non-null  float64\n",
      " 7   mean_chicken                 52161 non-null  float64\n",
      " 8   mean_duck                    52161 non-null  float64\n",
      " 9   mean_goat                    52161 non-null  float64\n",
      " 10  mean_horse                   52161 non-null  float64\n",
      " 11  mean_pig                     52161 non-null  float64\n",
      " 12  mean_sheep                   52161 non-null  float64\n",
      " 13  sum_buffalo                  52161 non-null  float64\n",
      " 14  sum_cattle                   52161 non-null  float64\n",
      " 15  sum_chicken                  52161 non-null  float64\n",
      " 16  sum_goat                     52161 non-null  float64\n",
      " 17  sum_horse                    52161 non-null  float64\n",
      " 18  sum_pig                      52161 non-null  float64\n",
      " 19  sum_sheep                    52161 non-null  float64\n",
      " 20  area_usable_km2_buffalo      52161 non-null  float64\n",
      " 21  head_count_cattle            52161 non-null  float64\n",
      " 22  head_count_chicken           52161 non-null  float64\n",
      " 23  head_count_goat              52161 non-null  float64\n",
      " 24  head_count_horse             39885 non-null  float64\n",
      " 25  head_count_sheep             52161 non-null  float64\n",
      " 26  std_dev_cattle               52161 non-null  float64\n",
      " 27  std_dev_chicken              52161 non-null  float64\n",
      " 28  std_dev_duck                 39885 non-null  float64\n",
      " 29  std_dev_goat                 52161 non-null  float64\n",
      " 30  std_dev_horse                39885 non-null  float64\n",
      " 31  std_dev_pig                  52161 non-null  float64\n",
      " 32  std_dev_sheep                52161 non-null  float64\n",
      " 33  std_error_cattle             52161 non-null  float64\n",
      " 34  std_error_goat               52161 non-null  float64\n",
      " 35  std_error_sheep              52161 non-null  float64\n",
      " 36  usable_area_percent_buffalo  52161 non-null  float64\n",
      " 37  growth_rate_wm_buffalo       37761 non-null  float64\n",
      " 38  growth_rate_wm_cattle        49077 non-null  float64\n",
      " 39  growth_rate_wm_chicken       49059 non-null  float64\n",
      " 40  growth_rate_wm_duck          49041 non-null  float64\n",
      " 41  growth_rate_wm_goat          49066 non-null  float64\n",
      " 42  growth_rate_wm_horse         49077 non-null  float64\n",
      " 43  growth_rate_wm_pig           49073 non-null  float64\n",
      " 44  growth_rate_wm_sheep         49073 non-null  float64\n",
      "dtypes: float64(43), int64(1), object(1)\n",
      "memory usage: 17.9+ MB\n",
      "\n",
      "\n",
      "First Row:\n",
      "fips                                    01001\n",
      "year                                     2003\n",
      "MeanLifeExpectency                  74.628765\n",
      "count_buffalo                            35.0\n",
      "count_cattle                             35.0\n",
      "mean_buffalo                        65.904788\n",
      "mean_cattle                        860.999684\n",
      "mean_chicken                      1423.557155\n",
      "mean_duck                            8.388511\n",
      "mean_goat                            41.50896\n",
      "mean_horse                          60.749474\n",
      "mean_pig                             8.453753\n",
      "mean_sheep                          10.756526\n",
      "sum_buffalo                     101469.084534\n",
      "sum_cattle                     1325622.201178\n",
      "sum_chicken                    2191753.381819\n",
      "sum_goat                         63908.500468\n",
      "sum_horse                        93531.801286\n",
      "sum_pig                          13015.664184\n",
      "sum_sheep                        16561.085888\n",
      "area_usable_km2_buffalo            571.613304\n",
      "head_count_cattle               492158.874128\n",
      "head_count_chicken              813724.208756\n",
      "head_count_goat                  23727.073679\n",
      "head_count_horse                  34725.20751\n",
      "head_count_sheep                  6148.573385\n",
      "std_dev_cattle                     552.092442\n",
      "std_dev_chicken                   5136.264935\n",
      "std_dev_duck                         3.650081\n",
      "std_dev_goat                        15.734996\n",
      "std_dev_horse                       71.287758\n",
      "std_dev_pig                          17.25002\n",
      "std_dev_sheep                        3.970536\n",
      "std_error_cattle                    93.320655\n",
      "std_error_goat                         2.6597\n",
      "std_error_sheep                      0.671143\n",
      "usable_area_percent_buffalo         36.517602\n",
      "growth_rate_wm_buffalo                    NaN\n",
      "growth_rate_wm_cattle                     NaN\n",
      "growth_rate_wm_chicken                    NaN\n",
      "growth_rate_wm_duck                       NaN\n",
      "growth_rate_wm_goat                       NaN\n",
      "growth_rate_wm_horse                      NaN\n",
      "growth_rate_wm_pig                        NaN\n",
      "growth_rate_wm_sheep                      NaN\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "Column Headers:\n",
      "['fips', 'year', 'MeanLifeExpectency', 'count_buffalo', 'count_cattle', 'mean_buffalo', 'mean_cattle', 'mean_chicken', 'mean_duck', 'mean_goat', 'mean_horse', 'mean_pig', 'mean_sheep', 'sum_buffalo', 'sum_cattle', 'sum_chicken', 'sum_goat', 'sum_horse', 'sum_pig', 'sum_sheep', 'area_usable_km2_buffalo', 'head_count_cattle', 'head_count_chicken', 'head_count_goat', 'head_count_horse', 'head_count_sheep', 'std_dev_cattle', 'std_dev_chicken', 'std_dev_duck', 'std_dev_goat', 'std_dev_horse', 'std_dev_pig', 'std_dev_sheep', 'std_error_cattle', 'std_error_goat', 'std_error_sheep', 'usable_area_percent_buffalo', 'growth_rate_wm_buffalo', 'growth_rate_wm_cattle', 'growth_rate_wm_chicken', 'growth_rate_wm_duck', 'growth_rate_wm_goat', 'growth_rate_wm_horse', 'growth_rate_wm_pig', 'growth_rate_wm_sheep']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizahmad/miniforge3/envs/geo_ml/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/faizahmad/miniforge3/envs/geo_ml/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is already a pandas DataFrame loaded from a CSV\n",
    "# Example: df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# 1. Check data statistics for numerical columns\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Display information about the DataFrame (including data types and non-null counts)\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Display the first row of the DataFrame\n",
    "print(\"First Row:\")\n",
    "print(df.iloc[0]) # or df.head(1)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Display all column headers (claims head)\n",
    "print(\"Column Headers:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25335b5",
   "metadata": {},
   "source": [
    "In a separte notebook ML codes are provided"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
